{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import gensim\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Load the table `compaints_users` for the complaint text and product ID, and the `products` table to find the product and sub-product\n",
    "df = pd.read_csv('data/complaints_users.csv')\n",
    "df2 = pd.read_csv('data/products.csv')\n",
    "df = df.merge(df2, how='left', on='PRODUCT_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove product IDs which have fewer than 100 complaints\n",
    "df['COMPLAINT_COUNTS'] = df.groupby('PRODUCT_ID')['COMPLAINT_ID'].transform('count')\n",
    "df = df[df['COMPLAINT_COUNTS'] > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPLAINT_ID</th>\n",
       "      <th>COMPLAINT_TEXT</th>\n",
       "      <th>WAS_USER_DISPUTED</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRODUCT_ID</th>\n",
       "      <th>ISSUE_ID</th>\n",
       "      <th>MAIN_PRODUCT</th>\n",
       "      <th>SUB_PRODUCT</th>\n",
       "      <th>COMPLAINT_COUNTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3184195</td>\n",
       "      <td>XXXX  and Transunion are reporting incorrectly...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/19/2019</td>\n",
       "      <td>26</td>\n",
       "      <td>253</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>89994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3184692</td>\n",
       "      <td>XXXX and Transunion are reporting incorrectly ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/19/2019</td>\n",
       "      <td>26</td>\n",
       "      <td>253</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>89994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3183613</td>\n",
       "      <td>XXXX, XXXX, and Experian need to remove the co...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/18/2019</td>\n",
       "      <td>26</td>\n",
       "      <td>165</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>89994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3182430</td>\n",
       "      <td>3 company with inconsistencies, violations and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/17/2019</td>\n",
       "      <td>26</td>\n",
       "      <td>253</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>89994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3182218</td>\n",
       "      <td>I have a personal loan from Patriot finance. T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03/17/2019</td>\n",
       "      <td>26</td>\n",
       "      <td>165</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>89994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   COMPLAINT_ID                                     COMPLAINT_TEXT  \\\n",
       "0       3184195  XXXX  and Transunion are reporting incorrectly...   \n",
       "1       3184692  XXXX and Transunion are reporting incorrectly ...   \n",
       "2       3183613  XXXX, XXXX, and Experian need to remove the co...   \n",
       "3       3182430  3 company with inconsistencies, violations and...   \n",
       "4       3182218  I have a personal loan from Patriot finance. T...   \n",
       "\n",
       "  WAS_USER_DISPUTED        DATE  PRODUCT_ID  ISSUE_ID  \\\n",
       "0               NaN  03/19/2019          26       253   \n",
       "1               NaN  03/19/2019          26       253   \n",
       "2               NaN  03/18/2019          26       165   \n",
       "3               NaN  03/17/2019          26       253   \n",
       "4               NaN  03/17/2019          26       165   \n",
       "\n",
       "                                        MAIN_PRODUCT       SUB_PRODUCT  \\\n",
       "0  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "1  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "2  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "3  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "4  Credit reporting, credit repair services, or o...  Credit reporting   \n",
       "\n",
       "   COMPLAINT_COUNTS  \n",
       "0             89994  \n",
       "1             89994  \n",
       "2             89994  \n",
       "3             89994  \n",
       "4             89994  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df[['COMPLAINT_TEXT', 'MAIN_PRODUCT', 'SUB_PRODUCT']], test_size=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343774"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38198"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMPLAINT_TEXT</th>\n",
       "      <th>MAIN_PRODUCT</th>\n",
       "      <th>SUB_PRODUCT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377388</th>\n",
       "      <td>I have been trying to get a loan Modification ...</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Conventional fixed mortgage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145064</th>\n",
       "      <td>I have XXXX hard inquiries on my Transunion cr...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113361</th>\n",
       "      <td>As of today, I received my updated credit scor...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307551</th>\n",
       "      <td>I received a email from XXXX account services ...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154973</th>\n",
       "      <td>On XXXX XXXX I submitted a request to Transuni...</td>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Credit reporting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           COMPLAINT_TEXT  \\\n",
       "377388  I have been trying to get a loan Modification ...   \n",
       "145064  I have XXXX hard inquiries on my Transunion cr...   \n",
       "113361  As of today, I received my updated credit scor...   \n",
       "307551  I received a email from XXXX account services ...   \n",
       "154973  On XXXX XXXX I submitted a request to Transuni...   \n",
       "\n",
       "                                             MAIN_PRODUCT  \\\n",
       "377388                                           Mortgage   \n",
       "145064  Credit reporting, credit repair services, or o...   \n",
       "113361  Credit reporting, credit repair services, or o...   \n",
       "307551                                    Debt collection   \n",
       "154973  Credit reporting, credit repair services, or o...   \n",
       "\n",
       "                        SUB_PRODUCT  \n",
       "377388  Conventional fixed mortgage  \n",
       "145064             Credit reporting  \n",
       "113361             Credit reporting  \n",
       "307551                I do not know  \n",
       "154973             Credit reporting  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['LENGTH'] = train['COMPLAINT_TEXT'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train['COMPLAINT_TEXT'].tolist()\n",
    "train_len = train['LENGTH'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "train_text = [' '.join([token.lemma_ for token in nlp(doc)]) for doc in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"-PRON- have be try to get a loan Modification from Caliber Home Loans since XX / XX / XXXX . -PRON- have repeatedly fill out application per there request . -PRON- just send a denial letter state -PRON- be ineligible for any short term loan or interest only loan . -PRON- be suppose to be be evaluate for a repayment plan . now -PRON- have to start all over with an appeal process and -PRON- still wo n't accept -PRON- payment ! ! \\n there be discrepancy on the statement -PRON- have n't address . -PRON- say -PRON- accept a loan modification in XX / XX / XXXX - -PRON- have never sign nor see a modification document from -PRON- . -PRON- have payment reversal list which -PRON- have no idea what those be for and -PRON- send { $ 600.00 } to -PRON- ex wife who be n't suppose to be on the loan anymore .\",\n",
       " '-PRON- have XXXX hard inquiry on -PRON- Transunion credit report that -PRON- do not authorize . first from XXXX on XX / XX / XXXX . the second from XXXX on XX / XX / XXXX . third from XXXX on XX / XX / XXXX . the fourth be also from XXXX on the date of XX / XX / XXXX . -PRON- do not authorize these inquiry and do not know what -PRON- would be for . -PRON- have send letter to these company to get -PRON- remove but have get no response .',\n",
       " 'as of today , -PRON- receive -PRON- update credit score from XXXX , Transunion and XXXX . -PRON- FICO 8 score be show the follow : XXXX   - XXXX ; Transunion - XXXX ; XXXX - XXXX . when -PRON- pull up the old version FICO score from the credit bureaus for mortgage , -PRON- get the follow score : XXXX - XXXX ; Transunion - XXXX ; XXXX - XXXX . when -PRON- ask XXXX   why the big discrepencie in the score , -PRON- could not tell -PRON- why other than every agency be different . if -PRON- XXXX be report XXXX , XXXX   and Transunion should at least be a XXXX on the FICO 5 and 4 . -PRON- have be tell -PRON- several creditor and mortgage lender that if there be large than a 20 point difference , -PRON- need to be report . this be an unfair practice that XXXX and Transunion be do especially when -PRON- be work hard to reduce -PRON- debt ratio and instead of -PRON- be reward , -PRON- be be punish ? how do that work ?',\n",
       " '-PRON- receive a email from XXXX account service that a loan that -PRON- do not apply for be sell to National Credit Adjusters . this loan in question also show on -PRON- credit report . -PRON- have ask for help from the CFPB as well as request sign document for an application for credit or anything that -PRON- have in order to press charge . as of this date , nothing . -PRON- do -PRON- research on this company and there be no way -PRON- would apply to a payday loan service with the tactic this company employ . even bad than that -PRON- allow -PRON- ssn # to be use without -PRON- write or verbal consent .',\n",
       " 'on XXXX XXXX -PRON- submit a request to Transunion to review the new credit law information for removal of Public Records that be introduce in XXXX XXXX . instead Transunion launch a investigation into XXXX XXXX XXXX XXXX Tax Liens be report on -PRON- credit report . the result come back from Transunion as be verify but -PRON- receive no proof of how or with whom the Tax Liens be verify . -PRON- contact -PRON- Clerts Office here in XXXX Alabama and be inform -PRON- office do not report any information to credit bureaus ... the new credit law state the credit reporting agency agree to remove new or exist tax lien and judgment that do not contain at least XXXX out of the XXXX piece of identify information . neither of the ( XXXX XXXX tax Liens that be report on -PRON- Transunion file contain at least XXXX identify piece of -PRON- information ..']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [doc.lower().replace('\\n', '',) for doc in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = [re.sub(\"[^a-zA-Z$ ]+\", '', doc) for doc in train_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pron have be try to get a loan modification from caliber home loans since xx  xx  xxxx  pron have repeatedly fill out application per there request  pron just send a denial letter state pron be ineligible for any short term loan or interest only loan  pron be suppose to be be evaluate for a repayment plan  now pron have to start all over with an appeal process and pron still wo nt accept pron payment    there be discrepancy on the statement pron have nt address  pron say pron accept a loan modification in xx  xx  xxxx  pron have never sign nor see a modification document from pron  pron have payment reversal list which pron have no idea what those be for and pron send  $   to pron ex wife who be nt suppose to be on the loan anymore ',\n",
       " 'pron have xxxx hard inquiry on pron transunion credit report that pron do not authorize  first from xxxx on xx  xx  xxxx  the second from xxxx on xx  xx  xxxx  third from xxxx on xx  xx  xxxx  the fourth be also from xxxx on the date of xx  xx  xxxx  pron do not authorize these inquiry and do not know what pron would be for  pron have send letter to these company to get pron remove but have get no response ',\n",
       " 'as of today  pron receive pron update credit score from xxxx  transunion and xxxx  pron fico  score be show the follow  xxxx    xxxx  transunion  xxxx  xxxx  xxxx  when pron pull up the old version fico score from the credit bureaus for mortgage  pron get the follow score  xxxx  xxxx  transunion  xxxx  xxxx  xxxx  when pron ask xxxx   why the big discrepencie in the score  pron could not tell pron why other than every agency be different  if pron xxxx be report xxxx  xxxx   and transunion should at least be a xxxx on the fico  and   pron have be tell pron several creditor and mortgage lender that if there be large than a  point difference  pron need to be report  this be an unfair practice that xxxx and transunion be do especially when pron be work hard to reduce pron debt ratio and instead of pron be reward  pron be be punish  how do that work ',\n",
       " 'pron receive a email from xxxx account service that a loan that pron do not apply for be sell to national credit adjusters  this loan in question also show on pron credit report  pron have ask for help from the cfpb as well as request sign document for an application for credit or anything that pron have in order to press charge  as of this date  nothing  pron do pron research on this company and there be no way pron would apply to a payday loan service with the tactic this company employ  even bad than that pron allow pron ssn  to be use without pron write or verbal consent ',\n",
       " 'on xxxx xxxx pron submit a request to transunion to review the new credit law information for removal of public records that be introduce in xxxx xxxx  instead transunion launch a investigation into xxxx xxxx xxxx xxxx tax liens be report on pron credit report  the result come back from transunion as be verify but pron receive no proof of how or with whom the tax liens be verify  pron contact pron clerts office here in xxxx alabama and be inform pron office do not report any information to credit bureaus  the new credit law state the credit reporting agency agree to remove new or exist tax lien and judgment that do not contain at least xxxx out of the xxxx piece of identify information  neither of the  xxxx xxxx tax liens that be report on pron transunion file contain at least xxxx identify piece of pron information ']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in doc if word not in stop_words] for doc in texts]\n",
    "\n",
    "def bigrams(words, bi_min=15, tri_min=10):\n",
    "    bigram = gensim.models.Phrases(words, min_count=bi_min)\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    return bigram_mod\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "    \n",
    "def get_corpus(texts):\n",
    "    words = list(sent_to_words(texts))\n",
    "    words = remove_stopwords(words)\n",
    "    bigram_mod = bigrams(words)\n",
    "    bigram = [bigram_mod[review] for review in words]\n",
    "    id2word = gensim.corpora.Dictionary(bigram)\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.35)\n",
    "    id2word.compactify()\n",
    "    corpus = [id2word.doc2bow(text) for text in bigram]\n",
    "    return corpus, id2word, bigram\n",
    "\n",
    "train_corpus, train_id2word, bigram_train = get_corpus(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_train = gensim.models.ldamulticore.LdaMulticore(\n",
    "                           corpus=train_corpus,\n",
    "                           num_topics=20,\n",
    "                           id2word=train_id2word,\n",
    "                           chunksize=100,\n",
    "                           workers=7, # Num. Processing Cores - 1\n",
    "                           passes=50,\n",
    "                           eval_every = 1,\n",
    "                           per_word_topics=True)\n",
    "lda_train.save('lda_train.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.061*\"consumer\" + 0.057*\"information\" + 0.028*\"law\" + 0.022*\"section\" + 0.021*\"fair\" + 0.019*\"fcra\" + 0.018*\"right\" + 0.018*\"violation\" + 0.016*\"must\" + 0.016*\"provide\" + 0.016*\"require\" + 0.015*\"act\" + 0.015*\"reporting_agency\" + 0.015*\"request\" + 0.014*\"reporting_act\"'),\n",
       " (1,\n",
       "  '0.161*\"loan\" + 0.039*\"payment\" + 0.022*\"student\" + 0.021*\"pay\" + 0.021*\"navient\" + 0.015*\"year\" + 0.015*\"make\" + 0.014*\"would\" + 0.013*\"interest_rate\" + 0.013*\"interest\" + 0.011*\"month\" + 0.011*\"amount\" + 0.010*\"time\" + 0.009*\"apply\" + 0.009*\"rate\"'),\n",
       " (2,\n",
       "  '0.100*\"inquiry\" + 0.067*\"remove\" + 0.032*\"company\" + 0.031*\"authorize\" + 0.027*\"unauthorized\" + 0.026*\"without\" + 0.021*\"pull\" + 0.018*\"inquire\" + 0.018*\"contact\" + 0.017*\"hard_inquiry\" + 0.014*\"please\" + 0.014*\"request\" + 0.013*\"transunion\" + 0.013*\"apply\" + 0.012*\"permission\"'),\n",
       " (3,\n",
       "  '0.056*\"bankruptcy\" + 0.056*\"court\" + 0.055*\"file\" + 0.034*\"attorney\" + 0.029*\"state\" + 0.027*\"case\" + 0.017*\"law\" + 0.014*\"chapter\" + 0.013*\"discharge\" + 0.013*\"legal\" + 0.012*\"lawsuit\" + 0.012*\"order\" + 0.011*\"include\" + 0.010*\"office\" + 0.010*\"judgment\"'),\n",
       " (4,\n",
       "  '0.826*\"xx\" + 0.026*\"date\" + 0.004*\"coinbase\" + 0.004*\"xxxxxxxx\" + 0.004*\"open\" + 0.003*\"since\" + 0.003*\"day\" + 0.003*\"receive\" + 0.003*\"status\" + 0.003*\"follow\" + 0.003*\"onxx\" + 0.002*\"show\" + 0.002*\"type\" + 0.002*\"last\" + 0.002*\"xxxxxx\"'),\n",
       " (5,\n",
       "  '0.049*\"tell\" + 0.040*\"would\" + 0.026*\"say\" + 0.024*\"speak\" + 0.023*\"ask\" + 0.021*\"receive\" + 0.019*\"back\" + 0.019*\"could\" + 0.017*\"day\" + 0.016*\"contact\" + 0.016*\"get\" + 0.015*\"phone\" + 0.015*\"time\" + 0.013*\"state\" + 0.012*\"representative\"'),\n",
       " (6,\n",
       "  '0.118*\"bank\" + 0.057*\"check\" + 0.040*\"money\" + 0.030*\"fund\" + 0.023*\"deposit\" + 0.017*\"wells_fargo\" + 0.017*\"transaction\" + 0.016*\"day\" + 0.016*\"checking\" + 0.014*\"fee\" + 0.013*\"transfer\" + 0.013*\"debit\" + 0.012*\"close\" + 0.012*\"cash\" + 0.011*\"branch\"'),\n",
       " (7,\n",
       "  '0.061*\"car\" + 0.037*\"insurance\" + 0.036*\"vehicle\" + 0.023*\"purchase\" + 0.023*\"finance\" + 0.023*\"pay\" + 0.023*\"company\" + 0.022*\"lease\" + 0.021*\"contract\" + 0.012*\"sign\" + 0.012*\"title\" + 0.011*\"move\" + 0.011*\"repair\" + 0.011*\"apartment\" + 0.011*\"auto\"'),\n",
       " (8,\n",
       "  '0.070*\"letter\" + 0.064*\"send\" + 0.049*\"request\" + 0.039*\"receive\" + 0.029*\"provide\" + 0.024*\"copy\" + 0.022*\"document\" + 0.022*\"state\" + 0.019*\"proof\" + 0.016*\"mail\" + 0.015*\"documentation\" + 0.015*\"response\" + 0.012*\"ask\" + 0.012*\"respond\" + 0.011*\"information\"'),\n",
       " (9,\n",
       "  '0.089*\"number\" + 0.055*\"address\" + 0.049*\"name\" + 0.045*\"information\" + 0.039*\"phone\" + 0.024*\"company\" + 0.018*\"contact\" + 0.017*\"personal\" + 0.015*\"social_security\" + 0.012*\"use\" + 0.012*\"person\" + 0.012*\"ask\" + 0.011*\"give\" + 0.010*\"stop\" + 0.010*\"never\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_train.print_topics(20,num_words=15)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vecs = []\n",
    "for i in range(len(train_text)):\n",
    "    top_topics = lda_train.get_document_topics(train_corpus[i], minimum_probability=0.0)\n",
    "    topic_vec = [top_topics[i][1] for i in range(20)]\n",
    "    topic_vec.append(train_len[i])  # length of complaint\n",
    "    train_vecs.append(topic_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Val f1: 0.347 +- 0.228\n",
      "Logisitic Regression SGD Val f1: 0.346 +- 0.250\n",
      "SVM Huber Val f1: 0.053 +- 0.126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(train_vecs)\n",
    "y = np.array(train['MAIN_PRODUCT'])\n",
    "\n",
    "kf = KFold(5, shuffle=True, random_state=42)\n",
    "cv_lr_f1, cv_lrsgd_f1, cv_svcsgd_f1,  = [], [], []\n",
    "\n",
    "for train_ind, val_ind in kf.split(X, y):\n",
    "    # Assign CV IDX\n",
    "    X_train, y_train = X[train_ind], y[train_ind]\n",
    "    X_val, y_val = X[val_ind], y[val_ind]\n",
    "    \n",
    "    # Scale Data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scale = scaler.fit_transform(X_train)\n",
    "    X_val_scale = scaler.transform(X_val)\n",
    "\n",
    "    # Logisitic Regression\n",
    "    lr = LogisticRegression(\n",
    "        class_weight= 'balanced',\n",
    "        solver='newton-cg',\n",
    "        fit_intercept=True,\n",
    "        multi_class='auto'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "\n",
    "    y_pred = lr.predict(X_val_scale)\n",
    "    cv_lr_f1.append(f1_score(y_val, y_pred, average=None))\n",
    "    \n",
    "    # Logistic Regression SGD\n",
    "    sgd = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        loss='log',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd.predict(X_val_scale)\n",
    "    cv_lrsgd_f1.append(f1_score(y_val, y_pred, average=None))\n",
    "    \n",
    "    # SGD Modified Huber\n",
    "    sgd_huber = linear_model.SGDClassifier(\n",
    "        max_iter=1000,\n",
    "        tol=1e-3,\n",
    "        alpha=20,\n",
    "        loss='modified_huber',\n",
    "        class_weight='balanced'\n",
    "    ).fit(X_train_scale, y_train)\n",
    "    \n",
    "    y_pred = sgd_huber.predict(X_val_scale)\n",
    "    cv_svcsgd_f1.append(f1_score(y_val, y_pred, average=None))\n",
    "\n",
    "print(f'Logistic Regression Val f1: {np.mean(cv_lr_f1):.3f} +- {np.std(cv_lr_f1):.3f}')\n",
    "print(f'Logisitic Regression SGD Val f1: {np.mean(cv_lrsgd_f1):.3f} +- {np.std(cv_lrsgd_f1):.3f}')\n",
    "print(f'SVM Huber Val f1: {np.mean(cv_svcsgd_f1):.3f} +- {np.std(cv_svcsgd_f1):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
